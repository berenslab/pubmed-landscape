{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from openTSNE import TSNE\n",
    "from openTSNE import affinity, initialization, TSNEEmbedding\n",
    "from openTSNE.affinity import Affinities\n",
    "\n",
    "import time\n",
    "\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pubmed_landscape_src.metrics import knn_accuracy_ls\n",
    "from pubmed_landscape_src.data import generate_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../../results/variables\")\n",
    "figures_path = Path(\"../../results/figures\")\n",
    "berenslab_data_path = Path(\"/gpfs01/berens/data/data/pubmed_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_pickle(berenslab_data_path / \"df_labeled_papers_subset\")\n",
    "df = df.reset_index(drop=True)\n",
    "abstracts = df[\"AbstractText\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmedbert_tokenizer(input_string):\n",
    "    \"The tokenizer should be a function that takes a string and returns an array of its tokens.\"\n",
    "\n",
    "    tokenizer_kwargs = dict(\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        #     return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = tokenizer(input_string, **tokenizer_kwargs)\n",
    "\n",
    "    return tokenizer.convert_ids_to_tokens(\n",
    "        inputs[\"input_ids\"], skip_special_tokens=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5948.01 MiB, increment: 1032.31 MiB\n",
      "CPU times: user 45min 31s, sys: 15.7 s, total: 45min 47s\n",
      "Wall time: 45min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TfidfVectorizer\n",
    "corpus = abstracts\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, tokenizer=pubmedbert_tokenizer)\n",
    "tfidf_features_1M_pubmedbert_tokenizer = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 29047)\n"
     ]
    }
   ],
   "source": [
    "# old: (1000000, 758111)\n",
    "print(tfidf_features_1M_pubmedbert_tokenizer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(variables_path / \"tfidf_features_1M_pubmedbert_tokenizer\", tfidf_features_1M_pubmedbert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 18038185984 bytes == 0x5af2000 @ \n",
      "tcmalloc: large alloc 18038185984 bytes == 0x43a030000 @ \n"
     ]
    }
   ],
   "source": [
    "#  results\n",
    "#tfidf_features_1M_pubmedbert_tokenizer = sp.sparse.load_npz(variables_path / \"tfidf_features_1M_pubmedbert_tokenizer.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 13167.90 MiB, increment: 7219.50 MiB\n",
      "CPU times: user 45min 42s, sys: 1h 21min 44s, total: 2h 7min 27s\n",
      "Wall time: 11min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=300, random_state=42, algorithm=\"arpack\")\n",
    "svd_data_1M_pubmedbert_tokenizer = svd.fit_transform(\n",
    "    tfidf_features_1M_pubmedbert_tokenizer\n",
    ")\n",
    "\n",
    "# save results\n",
    "np.save(\n",
    "    variables_path / \"svd_data_1M_pubmedbert_tokenizer\",\n",
    "    svd_data_1M_pubmedbert_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2400002048 bytes == 0x74930000 @ \n"
     ]
    }
   ],
   "source": [
    "# svd_data_1M_pubmedbert_tokenizer = np.load(variables_path / \"svd_data_1M_pubmedbert_tokenizer.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tsne(\n",
    "    embeddings, model_name, variables_path, rs=42, save_intermediates=True\n",
    "):\n",
    "    # affinities\n",
    "    A = affinity.Uniform(\n",
    "        embeddings,\n",
    "        k_neighbors=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # initialization\n",
    "    I = initialization.pca(embeddings, random_state=42)\n",
    "\n",
    "    if save_intermediates == True:\n",
    "        affinities_name = \"affinities_P_\" + model_name\n",
    "        sp.sparse.save_npz(variables_path / affinities_name, A.P)\n",
    "\n",
    "        initialization_name = \"initialization_\" + model_name\n",
    "        np.save(variables_path / initialization_name, I)\n",
    "\n",
    "    # t-SNE optimization\n",
    "    E = TSNEEmbedding(I, A, n_jobs=-1, random_state=42, verbose=True)\n",
    "\n",
    "    ## early exaggeration\n",
    "    E = E.optimize(\n",
    "        n_iter=125, exaggeration=12, momentum=0.5, n_jobs=-1, verbose=True\n",
    "    )\n",
    "\n",
    "    ## exaggeration annealing\n",
    "    exs = np.linspace(12, 1, 125)\n",
    "    for i in range(125):\n",
    "        E = E.optimize(\n",
    "            n_iter=1,\n",
    "            exaggeration=exs[i],\n",
    "            momentum=0.8,\n",
    "            n_jobs=-1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    ## final optimization without exaggeration\n",
    "    E = E.optimize(\n",
    "        n_iter=500, exaggeration=1, momentum=0.8, n_jobs=-1, verbose=True\n",
    "    )\n",
    "\n",
    "    tsne = np.array(E)\n",
    "\n",
    "    # save\n",
    "    tsne_name = \"tsne_\" + model_name\n",
    "    np.save(variables_path / tsne_name, tsne)\n",
    "\n",
    "    return tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Finding 10 nearest neighbors using Annoy approximate search using euclidean distance...\n",
      "   --> Time elapsed: 230.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/openTSNE/affinity.py:1219: FutureWarning: Using `mean` symmetrization, but the default behaviour is going to change to `max` in future versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Running optimization with exaggeration=12.00, lr=83333.33 for 125 iterations...\n",
      "Iteration   50, KL divergence 10.9196, 50 iterations in 16.6956 sec\n",
      "Iteration  100, KL divergence 10.1942, 50 iterations in 16.5724 sec\n",
      "   --> Time elapsed: 41.70 seconds\n",
      "===> Running optimization with exaggeration=12.00, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.91, lr=83953.96 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=11.82, lr=84583.90 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=11.73, lr=85223.37 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=11.65, lr=85872.58 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=11.56, lr=86531.75 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=11.47, lr=87201.13 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=11.38, lr=87880.94 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=11.29, lr=88571.43 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=11.20, lr=89272.86 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.11, lr=89985.49 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=11.02, lr=90709.58 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.94, lr=91445.43 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.85, lr=92193.31 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=10.76, lr=92953.52 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.67, lr=93726.38 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.58, lr=94512.20 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=10.49, lr=95311.30 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.40, lr=96124.03 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=10.31, lr=96950.74 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.23, lr=97791.80 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.14, lr=98647.57 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.05, lr=99518.46 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.96, lr=100404.86 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=9.87, lr=101307.19 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.78, lr=102225.89 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=9.69, lr=103161.40 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.60, lr=104114.19 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=9.52, lr=105084.75 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.43, lr=106073.57 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.34, lr=107081.17 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.25, lr=108108.11 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=9.16, lr=109154.93 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=9.07, lr=110222.22 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=8.98, lr=111310.59 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.90, lr=112420.67 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.81, lr=113553.11 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=8.72, lr=114708.60 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.63, lr=115887.85 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.54, lr=117091.60 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.45, lr=118320.61 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=8.36, lr=119575.70 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=8.27, lr=120857.70 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=8.19, lr=122167.49 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=8.10, lr=123505.98 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=8.01, lr=124874.12 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.92, lr=126272.91 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=7.83, lr=127703.40 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=7.74, lr=129166.67 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.65, lr=130663.86 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.56, lr=132196.16 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.48, lr=133764.83 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=7.39, lr=135371.18 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=7.30, lr=137016.57 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.21, lr=138702.46 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=7.12, lr=140430.35 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=7.03, lr=142201.83 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.94, lr=144018.58 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.85, lr=145882.35 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.77, lr=147794.99 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.68, lr=149758.45 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.59, lr=151774.79 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.50, lr=153846.15 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.41, lr=155974.84 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=6.32, lr=158163.27 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.23, lr=160413.97 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=6.15, lr=162729.66 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=6.06, lr=165113.18 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=5.97, lr=167567.57 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.88, lr=170096.02 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.79, lr=172701.95 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=5.70, lr=175388.97 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.61, lr=178160.92 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.52, lr=181021.90 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.44, lr=183976.26 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.35, lr=187028.66 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=5.26, lr=190184.05 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=5.17, lr=193447.74 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=5.08, lr=196825.40 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=4.99, lr=200323.10 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=4.90, lr=203947.37 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.81, lr=207705.19 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=4.73, lr=211604.10 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.64, lr=215652.17 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.55, lr=219858.16 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=4.46, lr=224231.46 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.37, lr=228782.29 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.28, lr=233521.66 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=4.19, lr=238461.54 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=4.10, lr=243614.93 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=4.02, lr=248995.98 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=3.93, lr=254620.12 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=3.84, lr=260504.20 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=3.75, lr=266666.67 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=3.66, lr=273127.75 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=3.57, lr=279909.71 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=3.48, lr=287037.04 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=3.40, lr=294536.82 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=3.31, lr=302439.02 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=3.22, lr=310776.94 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=3.13, lr=319587.63 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=3.04, lr=328912.47 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=2.95, lr=338797.81 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=2.86, lr=349295.77 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.77, lr=360465.12 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.69, lr=372372.37 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.60, lr=385093.17 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.51, lr=398713.83 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=2.42, lr=413333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=2.33, lr=429065.74 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.24, lr=446043.17 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.15, lr=464419.48 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=2.06, lr=484375.00 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=1.98, lr=506122.45 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=1.89, lr=529914.53 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=1.80, lr=556053.81 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=1.71, lr=584905.66 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=1.62, lr=616915.42 for 1 iterations...\n",
      "   --> Time elapsed: 0.36 seconds\n",
      "===> Running optimization with exaggeration=1.53, lr=652631.58 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=1.44, lr=692737.43 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=1.35, lr=738095.24 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=1.27, lr=789808.92 for 1 iterations...\n",
      "   --> Time elapsed: 0.32 seconds\n",
      "===> Running optimization with exaggeration=1.18, lr=849315.07 for 1 iterations...\n",
      "   --> Time elapsed: 0.34 seconds\n",
      "===> Running optimization with exaggeration=1.09, lr=918518.52 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=1000000.00 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=1000000.00 for 500 iterations...\n",
      "Iteration   50, KL divergence 7.1781, 50 iterations in 17.9312 sec\n",
      "Iteration  100, KL divergence 6.9277, 50 iterations in 21.2694 sec\n",
      "Iteration  150, KL divergence 6.7826, 50 iterations in 24.0037 sec\n",
      "Iteration  200, KL divergence 6.6828, 50 iterations in 24.3146 sec\n",
      "Iteration  250, KL divergence 6.6066, 50 iterations in 24.8725 sec\n",
      "Iteration  300, KL divergence 6.5461, 50 iterations in 27.8381 sec\n",
      "Iteration  350, KL divergence 6.4967, 50 iterations in 28.1950 sec\n",
      "Iteration  400, KL divergence 6.4547, 50 iterations in 29.0971 sec\n",
      "Iteration  450, KL divergence 6.4184, 50 iterations in 31.9086 sec\n",
      "Iteration  500, KL divergence 6.3869, 50 iterations in 32.0034 sec\n",
      "   --> Time elapsed: 261.44 seconds\n",
      "CPU times: user 1h 15min 34s, sys: 2min 38s, total: 1h 18min 13s\n",
      "Wall time: 10min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tsne_tfidf_pubmedbert_tokenizer = run_tsne(\n",
    "    svd_data_1M_pubmedbert_tokenizer,\n",
    "    \"tfidf_pubmedbert_tokenizer\",\n",
    "    variables_path=variables_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_pickle(berenslab_data_path / \"df_labeled_papers_subset\")\n",
    "df = df.reset_index(drop=True)\n",
    "colors = df[\"Colors\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_features_1M_pubmedbert_tokenizer = sp.sparse.load_npz(\n",
    "#     variables_path / \"tfidf_features_1M_pubmedbert_tokenizer.npz\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2400002048 bytes == 0x233da6000 @ \n"
     ]
    }
   ],
   "source": [
    "# svd_data_1M_pubmedbert_tokenizer = np.load(variables_path / \"svd_data_1M_pubmedbert_tokenizer.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_tfidf_pubmedbert_tokenizer = np.load(variables_path / \"tsne_tfidf_pubmedbert_tokenizer.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 19h 19min 56s, sys: 1min 34s, total: 1d 19h 21min 31s\n",
      "Wall time: 1h 30min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_tfidf_features_1M_pubmedbert_tokenizer = knn_accuracy_ls(\n",
    "    tfidf_features_1M_pubmedbert_tokenizer, colors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6154\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_tfidf_features_1M_pubmedbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 420 ms, total: 3min 29s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_svd_data_1M_pubmedbert_tokenizer = knn_accuracy_ls(\n",
    "    svd_data_1M_pubmedbert_tokenizer, colors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5618\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_svd_data_1M_pubmedbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 586 ms, total: 53.9 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_tsne_tfidf_pubmedbert_tokenizer = knn_accuracy_ls(\n",
    "    tsne_tfidf_pubmedbert_tokenizer, colors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5007\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_tsne_tfidf_pubmedbert_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
