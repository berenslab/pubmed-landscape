{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from openTSNE import TSNE\n",
    "from openTSNE import affinity, initialization, TSNEEmbedding\n",
    "from openTSNE.affinity import Affinities\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pubmed_landscape_src.metrics import knn_accuracy_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../../results/variables/bert-models\")\n",
    "figures_path = Path(\"../../results/figures/bert-models\")\n",
    "berenslab_data_path = Path(\"/gpfs01/berens/data/data/pubmed_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_pickle(berenslab_data_path / \"df_labeled_papers_subset\")\n",
    "df = df.reset_index(drop=True)\n",
    "abstracts = df[\"AbstractText\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5592.64 MiB, increment: 2881.86 MiB\n",
      "CPU times: user 1min 53s, sys: 3.82 s, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TfidfVectorizer\n",
    "corpus = abstracts\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features_1M = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 758111)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_features_1M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "sp.sparse.save_npz(variables_path / \"tfidf_features_1M\", tfidf_features_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 18038185984 bytes == 0x5af2000 @ \n",
      "tcmalloc: large alloc 18038185984 bytes == 0x43a030000 @ \n"
     ]
    }
   ],
   "source": [
    "#  results\n",
    "#tfidf_features_1M = sp.sparse.load_npz(variables_path / \"tfidf_features_1M.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 3645005824 bytes == 0x14d300000 @ \n",
      "tcmalloc: large alloc 3645005824 bytes == 0x231a66000 @ \n",
      "tcmalloc: large alloc 1819467776 bytes == 0x14d300000 @ \n",
      "tcmalloc: large alloc 1819467776 bytes == 0x1b9a2e000 @ \n",
      "tcmalloc: large alloc 2400002048 bytes == 0x231a66000 @ \n",
      "tcmalloc: large alloc 2400002048 bytes == 0x2c0b38000 @ \n",
      "tcmalloc: large alloc 2400002048 bytes == 0x231a66000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 17312.98 MiB, increment: 11717.75 MiB\n",
      "CPU times: user 3h 29min 38s, sys: 1h 36min 51s, total: 5h 6min 29s\n",
      "Wall time: 23min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=300, random_state=42, algorithm=\"arpack\")\n",
    "svd_data_1M = svd.fit_transform(tfidf_features_1M)\n",
    "\n",
    "# save results\n",
    "np.save(variables_path / \"svd_data_1M\", svd_data_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2400002048 bytes == 0x74930000 @ \n"
     ]
    }
   ],
   "source": [
    "svd_data_1M = np.load(variables_path / \"svd_data_1M.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tsne(\n",
    "    embeddings, model_name, variables_path, rs=42, save_intermediates=True\n",
    "):\n",
    "    # affinities\n",
    "    A = affinity.Uniform(\n",
    "        embeddings,\n",
    "        k_neighbors=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # initialization\n",
    "    I = initialization.pca(embeddings, random_state=42)\n",
    "\n",
    "    if save_intermediates == True:\n",
    "        affinities_name = \"affinities_P_\" + model_name\n",
    "        sp.sparse.save_npz(variables_path / affinities_name, A.P)\n",
    "\n",
    "        initialization_name = \"initialization_\" + model_name\n",
    "        np.save(variables_path / initialization_name, I)\n",
    "\n",
    "    # t-SNE optimization\n",
    "    E = TSNEEmbedding(I, A, n_jobs=-1, random_state=42, verbose=True)\n",
    "\n",
    "    ## early exaggeration\n",
    "    E = E.optimize(\n",
    "        n_iter=125, exaggeration=12, momentum=0.5, n_jobs=-1, verbose=True\n",
    "    )\n",
    "\n",
    "    ## exaggeration annealing\n",
    "    exs = np.linspace(12, 1, 125)\n",
    "    for i in range(125):\n",
    "        E = E.optimize(\n",
    "            n_iter=1,\n",
    "            exaggeration=exs[i],\n",
    "            momentum=0.8,\n",
    "            n_jobs=-1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    ## final optimization without exaggeration\n",
    "    E = E.optimize(\n",
    "        n_iter=500, exaggeration=1, momentum=0.8, n_jobs=-1, verbose=True\n",
    "    )\n",
    "\n",
    "    tsne = np.array(E)\n",
    "\n",
    "    # save\n",
    "    tsne_name = \"tsne_\" + model_name\n",
    "    np.save(variables_path / tsne_name, tsne)\n",
    "\n",
    "    return tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Finding 10 nearest neighbors using Annoy approximate search using euclidean distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1275691008 bytes == 0x13e1da000 @ \n",
      "tcmalloc: large alloc 1658404864 bytes == 0x1d0812000 @ \n",
      "tcmalloc: large alloc 2155921408 bytes == 0x233da6000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   --> Time elapsed: 228.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2400002048 bytes == 0x2b45b2000 @ \n",
      "tcmalloc: large alloc 2400002048 bytes == 0x343684000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Running optimization with exaggeration=12.00, lr=83333.33 for 125 iterations...\n",
      "Iteration   50, KL divergence 10.8997, 50 iterations in 22.4524 sec\n",
      "Iteration  100, KL divergence 10.1305, 50 iterations in 21.9770 sec\n",
      "   --> Time elapsed: 55.65 seconds\n",
      "===> Running optimization with exaggeration=12.00, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=11.91, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.82, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.73, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.65, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=11.56, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=11.47, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.38, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=11.29, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.45 seconds\n",
      "===> Running optimization with exaggeration=11.20, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=11.11, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=11.02, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.33 seconds\n",
      "===> Running optimization with exaggeration=10.94, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=10.85, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=10.76, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=10.67, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=10.58, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=10.49, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=10.40, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=10.31, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=10.23, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=10.14, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=10.05, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=9.96, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=9.87, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=9.78, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=9.69, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=9.60, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.47 seconds\n",
      "===> Running optimization with exaggeration=9.52, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.47 seconds\n",
      "===> Running optimization with exaggeration=9.43, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=9.34, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=9.25, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=9.16, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=9.07, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=8.98, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.47 seconds\n",
      "===> Running optimization with exaggeration=8.90, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.35 seconds\n",
      "===> Running optimization with exaggeration=8.81, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.52 seconds\n",
      "===> Running optimization with exaggeration=8.72, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=8.63, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=8.54, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=8.45, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=8.36, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=8.27, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=8.19, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=8.10, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=8.01, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=7.92, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=7.83, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.37 seconds\n",
      "===> Running optimization with exaggeration=7.74, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=7.65, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=7.56, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=7.48, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=7.39, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.53 seconds\n",
      "===> Running optimization with exaggeration=7.30, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=7.21, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=7.12, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.45 seconds\n",
      "===> Running optimization with exaggeration=7.03, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=6.94, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=6.85, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=6.77, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=6.68, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=6.59, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=6.50, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=6.41, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=6.32, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=6.23, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=6.15, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=6.06, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=5.97, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=5.88, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.45 seconds\n",
      "===> Running optimization with exaggeration=5.79, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=5.70, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.54 seconds\n",
      "===> Running optimization with exaggeration=5.61, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=5.52, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.48 seconds\n",
      "===> Running optimization with exaggeration=5.44, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=5.35, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.54 seconds\n",
      "===> Running optimization with exaggeration=5.26, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=5.17, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=5.08, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=4.99, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=4.90, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=4.81, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=4.73, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.52 seconds\n",
      "===> Running optimization with exaggeration=4.64, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.54 seconds\n",
      "===> Running optimization with exaggeration=4.55, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=4.46, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=4.37, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=4.28, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=4.19, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=4.10, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.55 seconds\n",
      "===> Running optimization with exaggeration=4.02, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.56 seconds\n",
      "===> Running optimization with exaggeration=3.93, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.45 seconds\n",
      "===> Running optimization with exaggeration=3.84, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=3.75, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=3.66, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=3.57, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=3.48, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=3.40, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.50 seconds\n",
      "===> Running optimization with exaggeration=3.31, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=3.22, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=3.13, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=3.04, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.38 seconds\n",
      "===> Running optimization with exaggeration=2.95, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.51 seconds\n",
      "===> Running optimization with exaggeration=2.86, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=2.77, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=2.69, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.47 seconds\n",
      "===> Running optimization with exaggeration=2.60, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.46 seconds\n",
      "===> Running optimization with exaggeration=2.51, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.56 seconds\n",
      "===> Running optimization with exaggeration=2.42, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=2.33, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.44 seconds\n",
      "===> Running optimization with exaggeration=2.24, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=2.15, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=2.06, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=1.98, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=1.89, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=1.80, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.42 seconds\n",
      "===> Running optimization with exaggeration=1.71, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=1.62, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.49 seconds\n",
      "===> Running optimization with exaggeration=1.53, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=1.44, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.39 seconds\n",
      "===> Running optimization with exaggeration=1.35, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.40 seconds\n",
      "===> Running optimization with exaggeration=1.27, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.43 seconds\n",
      "===> Running optimization with exaggeration=1.18, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.56 seconds\n",
      "===> Running optimization with exaggeration=1.09, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.58 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=83333.33 for 1 iterations...\n",
      "   --> Time elapsed: 0.41 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=83333.33 for 500 iterations...\n",
      "Iteration   50, KL divergence 7.6400, 50 iterations in 25.3794 sec\n",
      "Iteration  100, KL divergence 7.3756, 50 iterations in 24.5793 sec\n",
      "Iteration  150, KL divergence 7.1116, 50 iterations in 26.1528 sec\n",
      "Iteration  200, KL divergence 6.9148, 50 iterations in 27.8637 sec\n",
      "Iteration  250, KL divergence 6.7706, 50 iterations in 27.4668 sec\n",
      "Iteration  300, KL divergence 6.6617, 50 iterations in 29.4229 sec\n",
      "Iteration  350, KL divergence 6.5771, 50 iterations in 31.7348 sec\n",
      "Iteration  400, KL divergence 6.5091, 50 iterations in 32.9769 sec\n",
      "Iteration  450, KL divergence 6.4536, 50 iterations in 34.6777 sec\n",
      "Iteration  500, KL divergence 6.4072, 50 iterations in 38.1996 sec\n",
      "   --> Time elapsed: 298.46 seconds\n",
      "CPU times: user 58min 8s, sys: 2min 51s, total: 1h 1min\n",
      "Wall time: 11min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tsne_tfidf = run_tsne(svd_data_1M, \"tfidf\", variables_path=variables_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN accuracies: RERUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_pickle(berenslab_data_path / \"df_labeled_papers_subset\")\n",
    "df = df.reset_index(drop=True)\n",
    "colors = df[\"Colors\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features_1M = sp.sparse.load_npz(\n",
    "    variables_path / \"tfidf_features_1M.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2400002048 bytes == 0x233da6000 @ \n"
     ]
    }
   ],
   "source": [
    "svd_data_1M = np.load(variables_path / \"svd_data_1M.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_tfidf = np.load(variables_path / \"tsne_tfidf.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 33s, sys: 3.82 s, total: 49min 37s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_tfidf_features_1M = knn_accuracy_ls(tfidf_features_1M, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_tfidf_features_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 54s, sys: 40min 16s, total: 1h 16min 10s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_svd_data_1M = knn_accuracy_ls(svd_data_1M, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5475\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_svd_data_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 13s, sys: 19min 48s, total: 31min 2s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_tsne_tfidf = knn_accuracy_ls(tsne_tfidf, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy_tsne_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
